{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Training\n",
    "This is our core work. We attack our initial hate speech model to find out our baseline accuracy. \n",
    "After that, we use adversarial training on the pre-trained Roberta model to see if we can \n",
    "improve the accuracy. This trained hate speech model will be attacked again to see if we can achieve any improvements.\n",
    "\n",
    "Following naming will be used below:\n",
    "- <strong>Pre-Trained Model:</strong> This is the [RoBERTa model ](https://huggingface.co/docs/transformers/model_doc/roberta) model from Huggingface\n",
    "- <strong>Initial Hate Speech Model:</strong> This is our RoBERTa model, which we trained on the Hate speech data set.\n",
    "- <strong>Trained Hate Speech Model:</strong> RoBERTa model, which was trained using adversarial training\n",
    "\n",
    "\n",
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers[torch]\n",
    "!pip3 install textattack[tensorflow,optional]\n",
    "#!pip3 install --force-reinstall textattack\n",
    "!pip3 install --upgrade tensorflow\n",
    "#!pip install accelerate -U\n",
    "!pip3 install sentence_transformers\n",
    "!pip3 install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marinjaprincipe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marinjaprincipe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# textattack packages\n",
    "import textattack\n",
    "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "\n",
    "# transformers packages\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "from trainer import Trainer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Analysis of the Initial Hate Speech Model\n",
    "As the first step we want to get a baseline of the accuracy of our Initial Hate Speech Model (the training of this model is done in notebook inital_hate_speech_model_training.ipynb). \n",
    "To do so we attack the Initial Hate Speech Model with our custom attack and see how it performes.\n",
    "\n",
    "In a second step, all susccessfull attacks will be used to traine the pre-trained model in order to achieve a better result.\n",
    "\n",
    "#### Data cleaning\n",
    "Since the data needs to be cleaned for the attack, we defined the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is copy from https://www.kaggle.com/code/soumyakushwaha/ethicalcommunicationai\n",
    "# ----------------------------------------\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub(r\"\\@w+|\\#\",'',text)\n",
    "    text = re.sub(r\"[^\\w\\s]\",'',text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    tweet_tokens = word_tokenize(text)\n",
    "    filtered_tweets=[w for w in tweet_tokens if not w in stopword] #removing stopwords\n",
    "    return \" \".join(filtered_tweets)\n",
    "#--------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train data shape: (3003, 2)\n",
      "New Validation data shape: (643, 2)\n",
      "New Test data shape: (644, 2)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_TEXT_LENGTH = 512\n",
    "EPOCHS = 10\n",
    "MODEL_PATH = 'roberta_model.bin'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "labeled_data = pd.read_csv('./datasets/hate_speech_data.csv')\n",
    "# Hate Speech and Offensive Language Data: 25.3k total entries.\n",
    "# - Class 0: 1,430 entries (hate speech)\n",
    "# - Class 1: 19,190 entries (offensive language)\n",
    "# - Class 2: 4,163 entries (neither)\n",
    "\n",
    "# Processing labeled hate speech dataset\n",
    "hate_offensive_data = labeled_data[labeled_data['class'] != 2].copy()\n",
    "hate_offensive_data.loc[:, 'category'] = hate_offensive_data['class'].replace([0, 1], 1)\n",
    "hate_offensive_data = hate_offensive_data.rename(columns={'tweet': 'text'})\n",
    "\n",
    "# Test 1 ---\n",
    "# Select data for each class\n",
    "hate_speech_data = labeled_data[labeled_data['class'] == 0].copy()\n",
    "offensive_data = labeled_data[labeled_data['class'] == 1].copy()\n",
    "neither_data = labeled_data[labeled_data['class'] == 2].copy()\n",
    "sample_size = len(hate_speech_data)\n",
    "offensive_sample = offensive_data.sample(n=sample_size, random_state=SEED)\n",
    "neither_sample = neither_data.sample(n=sample_size, random_state=SEED)\n",
    "hate_speech_data['category'] = 1\n",
    "offensive_sample['category'] = 1\n",
    "neither_sample['category'] = 0\n",
    "sampled_data = pd.concat([hate_speech_data, offensive_sample, neither_sample], ignore_index=True)[['tweet', 'category']]\n",
    "sampled_data.rename(columns={'tweet': 'text', 'category': 'label'}, inplace=True)\n",
    "sampled_data['text'] = sampled_data['text'].apply(clean_text)  # Assuming clean_text is a defined function\n",
    "train_data, intermediate_data = train_test_split(sampled_data, test_size=0.3, random_state=SEED)\n",
    "validation_data, test_data = train_test_split(intermediate_data, test_size=0.5, random_state=SEED)\n",
    "train_tokens = tokenizer(train_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "validation_tokens = tokenizer(validation_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "test_tokens = tokenizer(test_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "print(f\"New Train data shape: {train_data.shape}\")\n",
    "print(f\"New Validation data shape: {validation_data.shape}\")\n",
    "print(f\"New Test data shape: {test_data.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load our Initial Hate Speech Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig()\n",
    "config.num_labels = 2\n",
    "roberta_base_config = {\n",
    "  \"architectures\": [\n",
    "    \"RobertaForMaskedLM\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"eos_token_id\": 2,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 514,\n",
    "  \"model_type\": \"roberta\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"pad_token_id\": 1,\n",
    "  \"type_vocab_size\": 1,\n",
    "  \"vocab_size\": 50265\n",
    "}\n",
    "\n",
    "for key in roberta_base_config.keys():\n",
    "    setattr(config, key, roberta_base_config[key])\n",
    "\n",
    "initial_hate_speech_model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "initial_hate_speech_model.load_state_dict(torch.load('roberta_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "initial_hate_speech_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Setup\n",
    "Now as we have loaded our trained model, we can attack it. To do so we try different attacks:\n",
    "\n",
    "- a custom attack\n",
    "- the Bert-attack from textattack\n",
    "- bae attack from textattack\n",
    "- textfooler from textattack\n",
    "\n",
    "\n",
    "### Custom Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_SEED = 71\n",
    "\n",
    "def create_custom_attack(model):\n",
    "    \n",
    "    # Define custom attack based on https://textattack.readthedocs.io/en/latest/api/attack.html used for training loop\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "    #UntagetedClassification: An untargeted attack on classification models which attempts\n",
    "    #to minimize the score of the correct label until it is no longer the predicted label.\n",
    "    goal_function = textattack.goal_functions.UntargetedClassification(model_wrapper)\n",
    "\n",
    "    constraints = [\n",
    "        RepeatModification(), # prevents the same word from being modified multiple times\n",
    "        StopwordModification(), # controls the modification of stopwords (e.g., \"the,\" \"is,\" \"and\")\n",
    "        WordEmbeddingDistance(min_cos_sim=0.9), # measures the cosine similarity between word embeddings to ensure that the replacement word is semantically similar\n",
    "    ]\n",
    "\n",
    "    transformation = textattack.transformations.word_swaps.word_swap_embedding.WordSwapEmbedding(max_candidates=50) # (50 is default)\n",
    "    search_method = textattack.search_methods.GreedyWordSwapWIR(wir_method=\"delete\")\n",
    "    custom_attack = textattack.Attack(goal_function, constraints, transformation, search_method) # perform the attack\n",
    "\n",
    "    return custom_attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.9\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Saving checkpoint under \"checkpoints/1697915223425.ta.chkpt\" at 2023-10-21 21:07:03 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Saving checkpoint under \"checkpoints/1697915235480.ta.chkpt\" at 2023-10-21 21:07:15 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Saving checkpoint under \"checkpoints/1697915246190.ta.chkpt\" at 2023-10-21 21:07:26 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Saving checkpoint under \"checkpoints/1697915259038.ta.chkpt\" at 2023-10-21 21:07:39 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 16 / 1 / 20: 100%|██████████| 20/20 [00:59<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 16     |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 95.0%  |\n",
      "| Accuracy under attack:        | 80.0%  |\n",
      "| Attack success rate:          | 15.79% |\n",
      "| Average perturbed word %:     | 12.76% |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 16.53  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x319206350>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x105866f10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31a4fa6d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x31a5cc810>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x318bfa650>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31b35ead0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x3191f2f10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30d600dd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30d5b1210>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31b0cde50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c829b750>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31a5cfb90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x31b381490>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30db68150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c73af310>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31b185890>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x318cc10d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30db51390>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31a42c0d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c72bb2d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(random_seed=ATTACK_SEED, num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "custom_attacker = textattack.Attacker(create_custom_attack(initial_hate_speech_model), dataset, attack_args)\n",
    "custom_attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.constraints.grammaticality import PartOfSpeech\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "\n",
    "def create_bae_attack(model):\n",
    "    \n",
    "    # Define custom attack based on https://textattack.readthedocs.io/en/latest/api/attack.html used for training loop\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "    #UntagetedClassification: An untargeted attack on classification models which attempts\n",
    "    #to minimize the score of the correct label until it is no longer the predicted label.\n",
    "    goal_function = textattack.goal_functions.UntargetedClassification(model_wrapper)\n",
    "\n",
    "    constraints = [\n",
    "        RepeatModification(), # prevents the same word from being modified multiple times\n",
    "        StopwordModification(), # controls the modification of stopwords (e.g., \"the,\" \"is,\" \"and\")\n",
    "        PartOfSpeech(allow_verb_noun_swap=True),\n",
    "    ]\n",
    "\n",
    "    transformation = textattack.transformations.word_swaps.word_swap_embedding.WordSwapEmbedding(max_candidates=50) # (50 is default)\n",
    "    search_method = textattack.search_methods.GreedyWordSwapWIR(wir_method=\"delete\")\n",
    "    bae_attack = textattack.Attack(goal_function, constraints, transformation, search_method) # perform the attack\n",
    "\n",
    "    return bae_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697989689915.ta.chkpt\" at 2023-10-22 17:48:09 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697989754272.ta.chkpt\" at 2023-10-22 17:49:14 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697989816537.ta.chkpt\" at 2023-10-22 17:50:16 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697989920467.ta.chkpt\" at 2023-10-22 17:52:00 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 18 / 1 / 1 / 20: 100%|██████████| 20/20 [05:31<00:00, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 18     |\n",
      "| Number of failed attacks:     | 1      |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 95.0%  |\n",
      "| Accuracy under attack:        | 5.0%   |\n",
      "| Attack success rate:          | 94.74% |\n",
      "| Average perturbed word %:     | 31.0%  |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 110.11 |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35ebffe10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35cb8bb50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ed57110>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x33c91ec90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ef4c150>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35cc89090>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ef0b1d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30ef1bed0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x33cc1ee90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35cb8bbd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30c92fe50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35cb1fe10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x30ef0bf50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ca1a550>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35ec30690>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x346240a10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35eb373d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ee91250>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35eb7dd90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ee890d0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(random_seed=ATTACK_SEED, num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "custom_attacker = textattack.Attacker(create_bae_attack(initial_hate_speech_model), dataset, attack_args)\n",
    "custom_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model on the Attacked Data\n",
    "We use now the attacking data to retrain our model again. For the training we use the trainer of the textattack library.\n",
    "First we setup the evaluation and training dataset as well as the training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Defin training base on https://textattack.readthedocs.io/en/latest/api/trainer.html\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "pretrained_roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "pretrained_roberta_model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(pretrained_roberta_model, tokenizer)\n",
    "\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "eval_dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "temp_train = list(train_data.itertuples(index=False, name=None))\n",
    "train_dataset = textattack.datasets.Dataset(temp_train)\n",
    "training_args = textattack.TrainingArgs(\n",
    "    num_epochs=3,\n",
    "    num_clean_epochs=1,\n",
    "    num_train_adv_examples=1000, #500 also ok\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    log_to_tb=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Custom Attack Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: `model_wrapper` and the victim model of `attack` are not the same model.\n",
      "textattack: Writing logs to ./outputs/2023-10-21-21-18-58-414556/train_log.txt.\n",
      "textattack: Wrote original training args to ./outputs/2023-10-21-21-18-58-414556/training_args.json.\n",
      "textattack: ***** Running training *****\n",
      "textattack:   Num examples = 3003\n",
      "textattack:   Num epochs = 3\n",
      "textattack:   Num clean epochs = 1\n",
      "textattack:   Instantaneous batch size per device = 8\n",
      "textattack:   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "textattack:   Gradient accumulation steps = 4\n",
      "textattack:   Total optimization steps = 346\n",
      "textattack: ==========================================================\n",
      "textattack: Epoch 1\n",
      "textattack: Running clean epoch 1/1\n",
      "Loss 0.61639: 100%|██████████| 376/376 [42:05<00:00,  6.72s/it]\n",
      "textattack: Train accuracy: 59.11%\n",
      "textattack: Eval accuracy: 84.29%\n",
      "textattack: Best score found. Saved model to ./outputs/2023-10-21-21-18-58-414556/best_model/\n",
      "textattack: ==========================================================\n",
      "textattack: Epoch 2\n",
      "textattack: Attacking model to generate new adversarial training set...\n",
      "[Succeeded / Failed / Skipped / Total] 435 / 2055 / 513 / 3003:  44%|████▎     | 435/1000 [2:05:11<2:42:36, 17.27s/it]\n",
      "textattack: Total number of attack results: 3003\n",
      "textattack: Attack success rate: 17.47% [435 / 2490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 0.46836: 100%|██████████| 430/430 [8:50:54<00:00, 74.08s/it]     \n",
      "textattack: Train accuracy: 84.58%\n",
      "textattack: Eval accuracy: 91.60%\n",
      "textattack: Best score found. Saved model to ./outputs/2023-10-21-21-18-58-414556/best_model/\n",
      "textattack: ==========================================================\n",
      "textattack: Epoch 3\n",
      "textattack: Attacking model to generate new adversarial training set...\n",
      "[Succeeded / Failed / Skipped / Total] 310 / 2524 / 169 / 3003:  31%|███       | 310/1000 [2:55:44<6:31:09, 34.01s/it]\n",
      "textattack: Total number of attack results: 3003\n",
      "textattack: Attack success rate: 10.94% [310 / 2834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 0.39479: 100%|██████████| 415/415 [46:32<00:00,  6.73s/it]\n",
      "textattack: Train accuracy: 89.92%\n",
      "textattack: Eval accuracy: 91.45%\n",
      "textattack: Wrote README to ./outputs/2023-10-21-21-18-58-414556/README.md.\n",
      "textattack: Eval accuracy: 91.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9144634525660964"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_attack_trainer_on_pretrained_model = Trainer(\n",
    "    pretrained_roberta_model_wrapper,\n",
    "    \"classification\",\n",
    "    create_custom_attack(pretrained_roberta_model),\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    training_args\n",
    ")\n",
    "custom_attack_trainer_on_pretrained_model.train()\n",
    "\n",
    "custom_attack_trainer_on_pretrained_model.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adverserial Training with Inital Hate Speech Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defin training base on https://textattack.readthedocs.io/en/latest/api/trainer.html\n",
    "initial_hate_speech_model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "initial_hate_speech_model.load_state_dict(torch.load('roberta_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "initial_hate_speech_model.eval()\n",
    "initial_hate_speech_model.to(map_location)\n",
    "initial_hate_speech_model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(initial_hate_speech_model, tokenizer)\n",
    "\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "eval_dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "temp_train = list(train_data.itertuples(index=False, name=None))\n",
    "train_dataset = textattack.datasets.Dataset(temp_train)\n",
    "training_args = textattack.TrainingArgs(\n",
    "    num_epochs=3,\n",
    "    num_clean_epochs=1,\n",
    "    num_train_adv_examples=1000,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    log_to_tb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: `model_wrapper` and the victim model of `attack` are not the same model.\n",
      "textattack: Writing logs to ./outputs/2023-10-21-21-18-58-414556/train_log.txt.\n",
      "textattack: Wrote original training args to ./outputs/2023-10-21-21-18-58-414556/training_args.json.\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "textattack: ***** Running training *****\n",
      "textattack:   Num examples = 3003\n",
      "textattack:   Num epochs = 3\n",
      "textattack:   Num clean epochs = 1\n",
      "textattack:   Instantaneous batch size per device = 8\n",
      "textattack:   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "textattack:   Gradient accumulation steps = 4\n",
      "textattack:   Total optimization steps = 346\n",
      "textattack: ==========================================================\n",
      "textattack: Epoch 1\n",
      "textattack: Running clean epoch 1/1\n",
      "Loss 0.00063:   1%|          | 3/376 [00:20<42:12,  6.79s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "custom_attack_trainer_on_initial_hate_speech_model = Trainer(\n",
    "    initial_hate_speech_model_wrapper,\n",
    "    \"classification\",\n",
    "    create_custom_attack(initial_hate_speech_model),\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    training_args\n",
    ")\n",
    "custom_attack_trainer_on_pretrained_model.train()\n",
    "\n",
    "custom_attack_trainer_on_pretrained_model.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Adverserial Trained Models\n",
    "\n",
    "#### Custom Attack Trainer Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_attack_trainer_on_pretrained_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_attack_trainer_on_initial_hate_speech_model.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Attack the Trained Hate Speech Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.9\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 5 / 0 / 5:  25%|██▌       | 5/20 [00:20<01:01,  4.08s/it]textattack: Saving checkpoint under \"checkpoints/1697972050429.ta.chkpt\" at 2023-10-22 12:54:10 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 10 / 0 / 10:  50%|█████     | 10/20 [00:32<00:32,  3.23s/it]textattack: Saving checkpoint under \"checkpoints/1697972062347.ta.chkpt\" at 2023-10-22 12:54:22 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 14 / 1 / 15:  75%|███████▌  | 15/20 [00:43<00:14,  2.88s/it]textattack: Saving checkpoint under \"checkpoints/1697972073265.ta.chkpt\" at 2023-10-22 12:54:33 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 18 / 1 / 20: 100%|██████████| 20/20 [00:55<00:00,  2.75s/it]textattack: Saving checkpoint under \"checkpoints/1697972085043.ta.chkpt\" at 2023-10-22 12:54:45 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 18 / 1 / 20: 100%|██████████| 20/20 [00:55<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 1      |\n",
      "| Number of failed attacks:     | 18     |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 95.0%  |\n",
      "| Accuracy under attack:        | 90.0%  |\n",
      "| Attack success rate:          | 5.26%  |\n",
      "| Average perturbed word %:     | 16.67% |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 18.42  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c6f929d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c77b7210>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x3749444d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c8a16e90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x301fd66d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c8a899d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30bba5250>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30bc7c4d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c71cbe50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c5537e50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c8a14050>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c87dad90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x2c87db0d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30bc6ec90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c6e48150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c6e4b2d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x2c8a3f850>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x30b8f1050>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x2c71d6350>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x103f31310>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack with Custom Attack\n",
    "trained_hate_speech_model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "trained_hate_speech_model.load_state_dict(torch.load('outputs/2023-10-21-21-18-58-414556/best_model/pytorch_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "trained_hate_speech_model.eval()\n",
    "trained_hate_speech_model.to(map_location)\n",
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(random_seed=ATTACK_SEED, num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "custom_attacker = textattack.Attacker(create_custom_attack(trained_hate_speech_model), dataset, attack_args)\n",
    "custom_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Text Fooler Attack on Trained Hate Speech Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697990347642.ta.chkpt\" at 2023-10-22 17:59:07 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697990516602.ta.chkpt\" at 2023-10-22 18:01:56 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697990662146.ta.chkpt\" at 2023-10-22 18:04:22 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"checkpoints/1697990821089.ta.chkpt\" at 2023-10-22 18:07:01 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 18 / 2 / 0 / 20: 100%|██████████| 20/20 [13:37<00:00, 40.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 18     |\n",
      "| Number of failed attacks:     | 2      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 10.0%  |\n",
      "| Attack success rate:          | 90.0%  |\n",
      "| Average perturbed word %:     | 29.68% |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 111.2  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x33dc6bd50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x357fead10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ef436d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35ebd77d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35eb492d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35ebb3a10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x3577a81d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x345a66a10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x3441db3d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35eb6be10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x357ce2710>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30efbb350>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x342073d90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30e986710>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x33dadb1d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x34615ab50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35cb1c250>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30efee610>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x35140fbd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x30ee4ca10>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack with Custom Attack\n",
    "trained_hate_speech_model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "trained_hate_speech_model.load_state_dict(torch.load('outputs/2023-10-21-21-18-58-414556/best_model/pytorch_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(random_seed=ATTACK_SEED, num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "bae_attacker = textattack.Attacker(create_bae_attack(trained_hate_speech_model), dataset, attack_args)\n",
    "bae_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert attack trainer evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_attack_trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
