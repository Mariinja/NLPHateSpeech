{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install transformers[torch]\n",
    "#!pip3 install textattack[tensorflow,optional]\n",
    "#!pip3 install --force-reinstall textattack\n",
    "#!pip3 install --upgrade tensorflow\n",
    "#!pip install accelerate -U\n",
    "#!pip3 install sentence_transformers\n",
    "#!pip3 install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# textattack packages\n",
    "import textattack\n",
    "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "\n",
    "# transformers packages\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ROBERTA model\n",
    "As the first step we train de pre-trained roBERTa model on our hate speech dataset. The training of the pre-trained roBERTa model is done in an other file.\n",
    "\n",
    "#### Data cleaning\n",
    "Since the data needs to be cleaned for the training, we defined the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is copy from https://www.kaggle.com/code/soumyakushwaha/ethicalcommunicationai\n",
    "# ----------------------------------------\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub(r\"\\@w+|\\#\",'',text)\n",
    "    text = re.sub(r\"[^\\w\\s]\",'',text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    tweet_tokens = word_tokenize(text)\n",
    "    filtered_tweets=[w for w in tweet_tokens if not w in stopword] #removing stopwords\n",
    "    return \" \".join(filtered_tweets)\n",
    "#--------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load hate speech data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_TEXT_LENGTH = 512\n",
    "EPOCHS = 10\n",
    "MODEL_PATH = 'roberta_model.bin'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "labeled_data = pd.read_csv('/Users/marinjaprincipe/Documents/UZH/NPL/test/labeled_data 2.csv')\n",
    "# Hate Speech and Offensive Language Data: 25.3k total entries.\n",
    "# - Class 0: 1,430 entries (hate speech)\n",
    "# - Class 1: 19,190 entries (offensive language)\n",
    "# - Class 2: 4,163 entries (neither)\n",
    "\n",
    "# Processing labeled hate speech dataset\n",
    "hate_offensive_data = labeled_data[labeled_data['class'] != 2].copy()\n",
    "hate_offensive_data.loc[:, 'category'] = hate_offensive_data['class'].replace([0, 1], 1)\n",
    "hate_offensive_data = hate_offensive_data.rename(columns={'tweet': 'text'})\n",
    "\n",
    "# Test 1 ---\n",
    "# Select data for each class\n",
    "hate_speech_data = labeled_data[labeled_data['class'] == 0].copy()\n",
    "offensive_data = labeled_data[labeled_data['class'] == 1].copy()\n",
    "neither_data = labeled_data[labeled_data['class'] == 2].copy()\n",
    "sample_size = len(hate_speech_data)\n",
    "offensive_sample = offensive_data.sample(n=sample_size, random_state=SEED)\n",
    "neither_sample = neither_data.sample(n=sample_size, random_state=SEED)\n",
    "hate_speech_data['category'] = 1\n",
    "offensive_sample['category'] = 1\n",
    "neither_sample['category'] = 0\n",
    "sampled_data = pd.concat([hate_speech_data, offensive_sample, neither_sample], ignore_index=True)[['tweet', 'category']]\n",
    "sampled_data.rename(columns={'tweet': 'text', 'category': 'label'}, inplace=True)\n",
    "sampled_data['text'] = sampled_data['text'].apply(clean_text)  # Assuming clean_text is a defined function\n",
    "train_data, intermediate_data = train_test_split(sampled_data, test_size=0.3, random_state=SEED)\n",
    "validation_data, test_data = train_test_split(intermediate_data, test_size=0.5, random_state=SEED)\n",
    "train_tokens = tokenizer(train_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "validation_tokens = tokenizer(validation_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "test_tokens = tokenizer(test_data['text'].tolist(), padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt')\n",
    "print(f\"New Train data shape: {train_data.shape}\")\n",
    "print(f\"New Validation data shape: {validation_data.shape}\")\n",
    "print(f\"New Test data shape: {test_data.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig()\n",
    "config.num_labels = 2\n",
    "roberta_base_config = {\n",
    "  \"architectures\": [\n",
    "    \"RobertaForMaskedLM\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"eos_token_id\": 2,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 514,\n",
    "  \"model_type\": \"roberta\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"pad_token_id\": 1,\n",
    "  \"type_vocab_size\": 1,\n",
    "  \"vocab_size\": 50265\n",
    "}\n",
    "\n",
    "for key in roberta_base_config.keys():\n",
    "    setattr(config, key, roberta_base_config[key])\n",
    "\n",
    "model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "model.load_state_dict(torch.load('/Users/marinjaprincipe/Documents/UZH/NPL/test/roberta_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model.eval()\n",
    "model.to(map_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Setup\n",
    "Now as we have loaded our trained model, we can attack it. To do so we try different attacks:\n",
    "\n",
    "- a custom attack\n",
    "- the Bert-attack from textattack\n",
    "- bae attack from textattack\n",
    "- textfooler from textattack\n",
    "\n",
    "\n",
    "### Custom Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom attack based on https://textattack.readthedocs.io/en/latest/api/attack.html used for training loop\n",
    "model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "#UntagetedClassification: An untargeted attack on classification models which attempts\n",
    "#to minimize the score of the correct label until it is no longer the predicted label.\n",
    "goal_function = textattack.goal_functions.UntargetedClassification(model_wrapper)\n",
    "\n",
    "constraints = [\n",
    "    RepeatModification(), # prevents the same word from being modified multiple times\n",
    "    StopwordModification(), # controls the modification of stopwords (e.g., \"the,\" \"is,\" \"and\")\n",
    "    WordEmbeddingDistance(min_cos_sim=0.9), # measures the cosine similarity between word embeddings to ensure that the replacement word is semantically similar\n",
    "]\n",
    "\n",
    "transformation = textattack.transformations.word_swaps.word_swap_embedding.WordSwapEmbedding(max_candidates=50) # (50 is default)\n",
    "search_method = textattack.search_methods.GreedyWordSwapWIR(wir_method=\"delete\")\n",
    "custom_attack = textattack.Attack(goal_function, constraints, transformation, search_method) # perform the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.9\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 16 / 1 / 20: 100%|██████████| 20/20 [00:53<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 16     |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 95.0%  |\n",
      "| Accuracy under attack:        | 80.0%  |\n",
      "| Attack success rate:          | 15.79% |\n",
      "| Average perturbed word %:     | 18.64% |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 16.95  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x325799710>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c7812d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c391790>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x325269590>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c6b0150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d0f6bd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32c49bad0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32678aa50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c7329d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c6f16d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c1d7d10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c637e50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x32c384350>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32c717f90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d114490>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c272610>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c6c0910>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c52e1d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c6aac10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d36b750>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "custom_attacker = textattack.Attacker(custom_attack, dataset, attack_args)\n",
    "custom_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert Attack from textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Bert-attack from textattack based on https://textattack.readthedocs.io/en/latest/3recipes/attack_recipes.html#bert-attack\n",
    "\n",
    "bert_attack = textattack.attack_recipes.bert_attack_li_2020.BERTAttackLi2020.build(model_wrapper) # perform the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "bert_attacker = textattack.Attacker(bert_attack, dataset, attack_args)\n",
    "bert_attacker.attack_dataset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bae Attack from testattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Bert-attack from textattack based on https://textattack.readthedocs.io/en/latest/3recipes/attack_recipes.html#bert-attack\n",
    "\n",
    "bae_attack = textattack.attack_recipes.bae_garg_2019.BAEGarg2019.build(model_wrapper) # perform the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "bae_attacker = textattack.Attacker(bae_attack, dataset, attack_args)\n",
    "bae_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextFooler Attack from textattack\n",
    "A Strong Baseline for Natural Language Attack on Text Classification and Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Bert-attack from textattack based on https://textattack.readthedocs.io/en/latest/3recipes/attack_recipes.html#bert-attack\n",
    "\n",
    "textFooler_attack = textattack.attack_recipes.textfooler_jin_2019.TextFoolerJin2019.build(model_wrapper) # perform the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "textFooler_attacker = textattack.Attacker(textFooler_attack, dataset, attack_args)\n",
    "textFooler_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on the attacked data\n",
    "We use now the attacking data to retrain our model again. For the training we use the trainer of the textattack library.\n",
    "First we setup the evaluation and training dataset as well as the training arguments.\n",
    "\n",
    "TODO: Train our model instead of the pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rt lameassnerd braxton curti hoe ass nigga wen see ima smack like da lil bitch', 1), ('frankiejgrande ew queer white thirsty bitch', 1), ('decodnlyfe lupefiasco larellj another black man anything monkey always monkey chicago idiot', 1), ('rtnba drakes new shoes released nikejordan yes theres glitter shoes dudes fag', 1), ('rt thadisreal ladies nigga always wan na go party every weekend basically side hoe shopping', 1), ('fuck wit us tweakin hoe', 1), ('like really doubt even plays already got lot big man rotation committed bosh bird mcbob amp shawne', 0), ('niggah niggah niggah dont believe wacthh', 1), ('rt harmonlauren jennas faggot', 1), ('rt dignifiedpurity ive work chuckling time derekisnormal said revealing age keeps pussy fresh', 1)]\n",
      "1 <class 'int'>\n",
      "[('species birds reported chesterfield great backyard bird count many area', 0), ('butterfliesblue heard green tea makes lose weight imma coon explains watermelon', 0), ('rt idntwearcondoms u acted like hoe broke im wrong thinking u hoe along', 0), ('rt strocorleone thoughtsofrandy yummysworld deze hoes got past demons em yolo nigga lol hahahahaha', 1), ('joe stop telling pbo job couldnt even keep job teabagger florida morningjoe', 0), ('thought bitch trynna line', 1), ('rt mosoknowso rt troyave got interest tall skinny model bitches like women ass amp hips', 1), ('infidelpamelalc im going blame black man since always blame whitey im equal opportunity hater', 1), ('theomaxximus gerryshalloweenparty halloween yesterday stupid nigger', 1), ('bird got headache', 0)]\n"
     ]
    }
   ],
   "source": [
    "## Defin training base on https://textattack.readthedocs.io/en/latest/api/trainer.html\n",
    "pretrained_roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "eval_dataset = textattack.datasets.Dataset(temp)\n",
    "print(temp[:10])\n",
    "print(temp[1][1], type(temp[1][1]))\n",
    "\n",
    "temp_train = list(train_data.itertuples(index=False, name=None))\n",
    "train_dataset = textattack.datasets.Dataset(temp_train)\n",
    "print(temp_train[:10])\n",
    "training_args = textattack.TrainingArgs(\n",
    "    num_epochs=3,\n",
    "    num_clean_epochs=1,\n",
    "    num_train_adv_examples=200,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    log_to_tb=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run custom attack trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trainer Class\n",
    "=============\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers\n",
    "\n",
    "import textattack\n",
    "from textattack.shared.utils import logger\n",
    "\n",
    "\n",
    "from textattack.attack import Attack\n",
    "from textattack.attack_args import AttackArgs\n",
    "from textattack.attack_results import MaximizedAttackResult, SuccessfulAttackResult\n",
    "from textattack.attacker import Attacker\n",
    "from textattack.model_args import HUGGINGFACE_MODELS\n",
    "from textattack.models.helpers import LSTMForClassification, WordCNNForClassification\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "from textattack.training_args import CommandLineTrainingArgs, TrainingArgs\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Trainer is training and eval loop for adversarial training.\n",
    "\n",
    "    It is designed to work with PyTorch and Transformers models.\n",
    "\n",
    "    Args:\n",
    "        model_wrapper (:class:`~textattack.models.wrappers.ModelWrapper`):\n",
    "            Model wrapper containing both the model and the tokenizer.\n",
    "        task_type (:obj:`str`, `optional`, defaults to :obj:`\"classification\"`):\n",
    "            The task that the model is trained to perform.\n",
    "            Currently, :class:`~textattack.Trainer` supports two tasks: (1) :obj:`\"classification\"`, (2) :obj:`\"regression\"`.\n",
    "        attack (:class:`~textattack.Attack`):\n",
    "            :class:`~textattack.Attack` used to generate adversarial examples for training.\n",
    "        train_dataset (:class:`~textattack.datasets.Dataset`):\n",
    "            Dataset for training.\n",
    "        eval_dataset (:class:`~textattack.datasets.Dataset`):\n",
    "            Dataset for evaluation\n",
    "        training_args (:class:`~textattack.TrainingArgs`):\n",
    "            Arguments for training.\n",
    "\n",
    "    Example::\n",
    "\n",
    "        >>> import textattack\n",
    "        >>> import transformers\n",
    "\n",
    "        >>> model = transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "        >>> # We only use DeepWordBugGao2018 to demonstration purposes.\n",
    "        >>> attack = textattack.attack_recipes.DeepWordBugGao2018.build(model_wrapper)\n",
    "        >>> train_dataset = textattack.datasets.HuggingFaceDataset(\"imdb\", split=\"train\")\n",
    "        >>> eval_dataset = textattack.datasets.HuggingFaceDataset(\"imdb\", split=\"test\")\n",
    "\n",
    "        >>> # Train for 3 epochs with 1 initial clean epochs, 1000 adversarial examples per epoch, learning rate of 5e-5, and effective batch size of 32 (8x4).\n",
    "        >>> training_args = textattack.TrainingArgs(\n",
    "        ...     num_epochs=3,\n",
    "        ...     num_clean_epochs=1,\n",
    "        ...     num_train_adv_examples=1000,\n",
    "        ...     learning_rate=5e-5,\n",
    "        ...     per_device_train_batch_size=8,\n",
    "        ...     gradient_accumulation_steps=4,\n",
    "        ...     log_to_tb=True,\n",
    "        ... )\n",
    "\n",
    "        >>> trainer = textattack.Trainer(\n",
    "        ...     model_wrapper,\n",
    "        ...     \"classification\",\n",
    "        ...     attack,\n",
    "        ...     train_dataset,\n",
    "        ...     eval_dataset,\n",
    "        ...     training_args\n",
    "        ... )\n",
    "        >>> trainer.train()\n",
    "\n",
    "    .. note::\n",
    "        When using :class:`~textattack.Trainer` with `parallel=True` in :class:`~textattack.TrainingArgs`,\n",
    "        make sure to protect the “entry point” of the program by using :obj:`if __name__ == '__main__':`.\n",
    "        If not, each worker process used for generating adversarial examples will execute the training code again.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_wrapper,\n",
    "        task_type=\"classification\",\n",
    "        attack=None,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=None,\n",
    "        training_args=None,\n",
    "    ):\n",
    "        assert isinstance(\n",
    "            model_wrapper, ModelWrapper\n",
    "        ), f\"`model_wrapper` must be of type `textattack.models.wrappers.ModelWrapper`, but got type `{type(model_wrapper)}`.\"\n",
    "\n",
    "        # TODO: Support seq2seq training\n",
    "        assert task_type in {\n",
    "            \"classification\",\n",
    "            \"regression\",\n",
    "        }, '`task_type` must either be \"classification\" or \"regression\"'\n",
    "\n",
    "        if attack:\n",
    "            assert isinstance(\n",
    "                attack, Attack\n",
    "            ), f\"`attack` argument must be of type `textattack.Attack`, but got type of `{type(attack)}`.\"\n",
    "\n",
    "            if id(model_wrapper) != id(attack.goal_function.model):\n",
    "                logger.warn(\n",
    "                    \"`model_wrapper` and the victim model of `attack` are not the same model.\"\n",
    "                )\n",
    "\n",
    "        if train_dataset:\n",
    "            assert isinstance(\n",
    "                train_dataset, textattack.datasets.Dataset\n",
    "            ), f\"`train_dataset` must be of type `textattack.datasets.Dataset`, but got type `{type(train_dataset)}`.\"\n",
    "\n",
    "        if eval_dataset:\n",
    "            assert isinstance(\n",
    "                eval_dataset, textattack.datasets.Dataset\n",
    "            ), f\"`eval_dataset` must be of type `textattack.datasets.Dataset`, but got type `{type(eval_dataset)}`.\"\n",
    "\n",
    "        if training_args:\n",
    "            assert isinstance(\n",
    "                training_args, TrainingArgs\n",
    "            ), f\"`training_args` must be of type `textattack.TrainingArgs`, but got type `{type(training_args)}`.\"\n",
    "        else:\n",
    "            training_args = TrainingArgs()\n",
    "\n",
    "        if not hasattr(model_wrapper, \"model\"):\n",
    "            raise ValueError(\"Cannot detect `model` in `model_wrapper`\")\n",
    "        else:\n",
    "            assert isinstance(\n",
    "                model_wrapper.model, torch.nn.Module\n",
    "            ), f\"`model` in `model_wrapper` must be of type `torch.nn.Module`, but got type `{type(model_wrapper.model)}`.\"\n",
    "\n",
    "        if not hasattr(model_wrapper, \"tokenizer\"):\n",
    "            raise ValueError(\"Cannot detect `tokenizer` in `model_wrapper`\")\n",
    "\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.task_type = task_type\n",
    "        self.attack = attack\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.training_args = training_args\n",
    "\n",
    "        self._metric_name = (\n",
    "            \"pearson_correlation\" if self.task_type == \"regression\" else \"accuracy\"\n",
    "        )\n",
    "        if self.task_type == \"regression\":\n",
    "            self.loss_fct = torch.nn.MSELoss(reduction=\"none\")\n",
    "        else:\n",
    "            self.loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "        self._global_step = 0\n",
    "\n",
    "    def _generate_adversarial_examples(self, epoch):\n",
    "        \"\"\"Generate adversarial examples using attacker.\"\"\"\n",
    "        assert (\n",
    "            self.attack is not None\n",
    "        ), \"`attack` is `None` but attempting to generate adversarial examples.\"\n",
    "        base_file_name = f\"attack-train-{epoch}\"\n",
    "        log_file_name = os.path.join(self.training_args.output_dir, base_file_name)\n",
    "        logger.info(\"Attacking model to generate new adversarial training set...\")\n",
    "\n",
    "        if isinstance(self.training_args.num_train_adv_examples, float):\n",
    "            num_train_adv_examples = math.ceil(\n",
    "                len(self.train_dataset) * self.training_args.num_train_adv_examples\n",
    "            )\n",
    "        else:\n",
    "            num_train_adv_examples = self.training_args.num_train_adv_examples\n",
    "\n",
    "        attack_args = AttackArgs(\n",
    "            num_successful_examples=num_train_adv_examples,\n",
    "            num_examples_offset=0,\n",
    "            query_budget=self.training_args.query_budget_train,\n",
    "            shuffle=True,\n",
    "            parallel=self.training_args.parallel,\n",
    "            num_workers_per_device=self.training_args.attack_num_workers_per_device,\n",
    "            disable_stdout=True,\n",
    "            silent=True,\n",
    "            log_to_txt=log_file_name + \".txt\",\n",
    "            log_to_csv=log_file_name + \".csv\",\n",
    "        )\n",
    "\n",
    "        attacker = Attacker(self.attack, self.train_dataset, attack_args=attack_args)\n",
    "        results = attacker.attack_dataset()\n",
    "\n",
    "        attack_types = collections.Counter(r.__class__.__name__ for r in results)\n",
    "        total_attacks = (\n",
    "            attack_types[\"SuccessfulAttackResult\"] + attack_types[\"FailedAttackResult\"]\n",
    "        )\n",
    "        success_rate = attack_types[\"SuccessfulAttackResult\"] / total_attacks * 100\n",
    "        logger.info(f\"Total number of attack results: {len(results)}\")\n",
    "        logger.info(\n",
    "            f\"Attack success rate: {success_rate:.2f}% [{attack_types['SuccessfulAttackResult']} / {total_attacks}]\"\n",
    "        )\n",
    "        # TODO: This will produce a bug if we need to manipulate ground truth output.\n",
    "        adversarial_examples = [\n",
    "            (\n",
    "                list(r.perturbed_result.attacked_text._text_input.values()),\n",
    "                r.perturbed_result.ground_truth_output,\n",
    "                \"adversarial_example\",\n",
    "            )\n",
    "            for r in results\n",
    "            if isinstance(r, (SuccessfulAttackResult, MaximizedAttackResult))\n",
    "        ]\n",
    "        adversarial_dataset = textattack.datasets.Dataset(\n",
    "            adversarial_examples,\n",
    "            input_columns=self.train_dataset.input_columns,\n",
    "            label_map=self.train_dataset.label_map,\n",
    "            label_names=self.train_dataset.label_names,\n",
    "            output_scale_factor=self.train_dataset.output_scale_factor,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        return adversarial_dataset\n",
    "\n",
    "    def _print_training_args(\n",
    "        self, total_training_steps, train_batch_size, num_clean_epochs\n",
    "    ):\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(f\"  Num examples = {len(self.train_dataset)}\")\n",
    "        logger.info(f\"  Num epochs = {self.training_args.num_epochs}\")\n",
    "        logger.info(f\"  Num clean epochs = {num_clean_epochs}\")\n",
    "        logger.info(\n",
    "            f\"  Instantaneous batch size per device = {self.training_args.per_device_train_batch_size}\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"  Total train batch size (w. parallel, distributed & accumulation) = {train_batch_size * self.training_args.gradient_accumulation_steps}\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"  Gradient accumulation steps = {self.training_args.gradient_accumulation_steps}\"\n",
    "        )\n",
    "        logger.info(f\"  Total optimization steps = {total_training_steps}\")\n",
    "\n",
    "    def _save_model_checkpoint(\n",
    "        self, model, tokenizer, step=None, epoch=None, best=False, last=False\n",
    "    ):\n",
    "        # Save model checkpoint\n",
    "        if step:\n",
    "            dir_name = f\"checkpoint-step-{step}\"\n",
    "        if epoch:\n",
    "            dir_name = f\"checkpoint-epoch-{epoch}\"\n",
    "        if best:\n",
    "            dir_name = \"best_model\"\n",
    "        if last:\n",
    "            dir_name = \"last_model\"\n",
    "\n",
    "        output_dir = os.path.join(self.training_args.output_dir, dir_name)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model = model.module\n",
    "\n",
    "        if isinstance(model, (WordCNNForClassification, LSTMForClassification)):\n",
    "            model.save_pretrained(output_dir)\n",
    "        elif isinstance(model, transformers.PreTrainedModel):\n",
    "            model.save_pretrained(output_dir)\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "        else:\n",
    "            state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save(\n",
    "                state_dict,\n",
    "                os.path.join(output_dir, \"pytorch_model.bin\"),\n",
    "            )\n",
    "\n",
    "    def _tb_log(self, log, step):\n",
    "        if not hasattr(self, \"_tb_writer\"):\n",
    "            from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "            self._tb_writer = SummaryWriter(self.training_args.tb_log_dir)\n",
    "            self._tb_writer.add_hparams(self.training_args.__dict__, {})\n",
    "            self._tb_writer.flush()\n",
    "\n",
    "        for key in log:\n",
    "            self._tb_writer.add_scalar(key, log[key], step)\n",
    "\n",
    "    def _wandb_log(self, log, step):\n",
    "        if not hasattr(self, \"_wandb_init\"):\n",
    "            global wandb\n",
    "            import wandb\n",
    "\n",
    "            self._wandb_init = True\n",
    "            wandb.init(\n",
    "                project=self.training_args.wandb_project,\n",
    "                config=self.training_args.__dict__,\n",
    "            )\n",
    "\n",
    "        wandb.log(log, step=step)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, model, num_training_steps):\n",
    "        \"\"\"Returns optimizer and scheduler to use for training. If you are\n",
    "        overriding this method and do not want to use a scheduler, simply\n",
    "        return :obj:`None` for scheduler.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`torch.nn.Module`):\n",
    "                Model to be trained. Pass its parameters to optimizer for training.\n",
    "            num_training_steps (:obj:`int`):\n",
    "                Number of total training steps.\n",
    "        Returns:\n",
    "            Tuple of optimizer and scheduler :obj:`tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]`\n",
    "        \"\"\"\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model = model.module\n",
    "\n",
    "        if isinstance(model, transformers.PreTrainedModel):\n",
    "            # Reference https://huggingface.co/transformers/training.html\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "            no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p\n",
    "                        for n, p in param_optimizer\n",
    "                        if not any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": self.training_args.weight_decay,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                    ],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "\n",
    "            optimizer = transformers.optimization.AdamW(\n",
    "                optimizer_grouped_parameters, lr=self.training_args.learning_rate\n",
    "            )\n",
    "            if isinstance(self.training_args.num_warmup_steps, float):\n",
    "                num_warmup_steps = math.ceil(\n",
    "                    self.training_args.num_warmup_steps * num_training_steps\n",
    "                )\n",
    "            else:\n",
    "                num_warmup_steps = self.training_args.num_warmup_steps\n",
    "\n",
    "            scheduler = transformers.optimization.get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=num_training_steps,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(\n",
    "                filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                lr=self.training_args.learning_rate,\n",
    "            )\n",
    "            scheduler = None\n",
    "\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def get_train_dataloader(self, dataset, adv_dataset, batch_size):\n",
    "        \"\"\"Returns the :obj:`torch.utils.data.DataLoader` for training.\n",
    "\n",
    "        Args:\n",
    "            dataset (:class:`~textattack.datasets.Dataset`):\n",
    "                Original training dataset.\n",
    "            adv_dataset (:class:`~textattack.datasets.Dataset`):\n",
    "                Adversarial examples generated from the original training dataset. :obj:`None` if no adversarial attack takes place.\n",
    "            batch_size (:obj:`int`):\n",
    "                Batch size for training.\n",
    "        Returns:\n",
    "            :obj:`torch.utils.data.DataLoader`\n",
    "        \"\"\"\n",
    "        # TODO: Add pairing option where we can pair original examples with adversarial examples.\n",
    "        # Helper functions for collating data\n",
    "        def collate_fn(data):\n",
    "            input_texts = []\n",
    "            targets = []\n",
    "            is_adv_sample = []\n",
    "            for item in data:\n",
    "                if len(item) == 3:\n",
    "                    # `len(item)` is 3 for adversarial training dataset\n",
    "                    _input, label, adv = item\n",
    "                    if adv != \"adversarial_example\":\n",
    "                        raise ValueError(\n",
    "                            \"`item` has length of 3 but last element is not for marking if the item is an `adversarial example`.\"\n",
    "                        )\n",
    "                    else:\n",
    "                        is_adv_sample.append(True)\n",
    "                else:\n",
    "                    # else `len(item)` is 2.\n",
    "                    _input, label = item\n",
    "                    is_adv_sample.append(False)\n",
    "\n",
    "                if isinstance(_input, collections.OrderedDict):\n",
    "                    _input = tuple(_input.values())\n",
    "                else:\n",
    "                    _input = tuple(_input)\n",
    "\n",
    "                if len(_input) == 1:\n",
    "                    _input = _input[0]\n",
    "                input_texts.append(_input)\n",
    "                targets.append(label)\n",
    "\n",
    "            return input_texts, torch.tensor(targets), torch.tensor(is_adv_sample)\n",
    "\n",
    "        if adv_dataset:\n",
    "            dataset = torch.utils.data.ConcatDataset([dataset, adv_dataset])\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return train_dataloader\n",
    "\n",
    "    def get_eval_dataloader(self, dataset, batch_size):\n",
    "        \"\"\"Returns the :obj:`torch.utils.data.DataLoader` for evaluation.\n",
    "\n",
    "        Args:\n",
    "            dataset (:class:`~textattack.datasets.Dataset`):\n",
    "                Dataset to use for evaluation.\n",
    "            batch_size (:obj:`int`):\n",
    "                Batch size for evaluation.\n",
    "        Returns:\n",
    "            :obj:`torch.utils.data.DataLoader`\n",
    "        \"\"\"\n",
    "        # Helper functions for collating data\n",
    "        def collate_fn(data):\n",
    "            input_texts = []\n",
    "            targets = []\n",
    "            for _input, label in data:\n",
    "                if isinstance(_input, collections.OrderedDict):\n",
    "                    _input = tuple(_input.values())\n",
    "                else:\n",
    "                    _input = tuple(_input)\n",
    "\n",
    "                if len(_input) == 1:\n",
    "                    _input = _input[0]\n",
    "                input_texts.append(_input)\n",
    "                targets.append(label)\n",
    "            return input_texts, torch.tensor(targets)\n",
    "\n",
    "        eval_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return eval_dataloader\n",
    "\n",
    "    def training_step(self, model, tokenizer, batch):\n",
    "        \"\"\"Perform a single training step on a batch of inputs.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`torch.nn.Module`):\n",
    "                Model to train.\n",
    "            tokenizer:\n",
    "                Tokenizer used to tokenize input text.\n",
    "            batch (:obj:`tuple[list[str], torch.Tensor, torch.Tensor]`):\n",
    "                By default, this will be a tuple of input texts, targets, and boolean tensor indicating if the sample is an adversarial example.\n",
    "\n",
    "                .. note::\n",
    "                    If you override the :meth:`get_train_dataloader` method, then shape/type of :obj:`batch` will depend on how you created your batch.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`tuple[torch.Tensor, torch.Tensor, torch.Tensor]` where\n",
    "\n",
    "            - **loss**: :obj:`torch.FloatTensor` of shape 1 containing the loss.\n",
    "            - **preds**: :obj:`torch.FloatTensor` of model's prediction for the batch.\n",
    "            - **targets**: :obj:`torch.Tensor` of model's targets (e.g. labels, target values).\n",
    "        \"\"\"\n",
    "\n",
    "        input_texts, targets, is_adv_sample = batch\n",
    "        _targets = targets\n",
    "        targets = targets.to(textattack.shared.utils.device)\n",
    "\n",
    "        if isinstance(model, transformers.PreTrainedModel) or (\n",
    "            isinstance(model, torch.nn.DataParallel)\n",
    "            and isinstance(model.module, transformers.PreTrainedModel)\n",
    "        ):\n",
    "            input_ids = tokenizer(\n",
    "                input_texts,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "            )\n",
    "            input_ids.to(textattack.shared.utils.device)\n",
    "            logits = model(**input_ids)[0]\n",
    "        else:\n",
    "            input_ids = tokenizer(input_texts)\n",
    "            if not isinstance(input_ids, torch.Tensor):\n",
    "                input_ids = torch.tensor(input_ids)\n",
    "            input_ids = input_ids.to(textattack.shared.utils.device)\n",
    "            logits = model(input_ids)\n",
    "\n",
    "        if self.task_type == \"regression\":\n",
    "            loss = self.loss_fct(logits.squeeze(), targets.squeeze())\n",
    "            preds = logits\n",
    "        else:\n",
    "            loss = self.loss_fct(logits, targets)\n",
    "            preds = logits.argmax(dim=-1)\n",
    "\n",
    "        sample_weights = torch.ones(\n",
    "            is_adv_sample.size(), device=textattack.shared.utils.device\n",
    "        )\n",
    "        sample_weights[is_adv_sample] *= self.training_args.alpha\n",
    "        loss = loss * sample_weights\n",
    "        loss = torch.mean(loss)\n",
    "        preds = preds.cpu()\n",
    "\n",
    "        return loss, preds, _targets\n",
    "\n",
    "\n",
    "    def evaluate_step(self, model, tokenizer, batch):\n",
    "        \"\"\"Perform a single evaluation step on a batch of inputs.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`torch.nn.Module`):\n",
    "                Model to train.\n",
    "            tokenizer:\n",
    "                Tokenizer used to tokenize input text.\n",
    "            batch (:obj:`tuple[list[str], torch.Tensor]`):\n",
    "                By default, this will be a tuple of input texts and target tensors.\n",
    "\n",
    "                .. note::\n",
    "                    If you override the :meth:`get_eval_dataloader` method, then shape/type of :obj:`batch` will depend on how you created your batch.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`tuple[torch.Tensor, torch.Tensor]` where\n",
    "\n",
    "            - **preds**: :obj:`torch.FloatTensor` of model's prediction for the batch.\n",
    "            - **targets**: :obj:`torch.Tensor` of model's targets (e.g. labels, target values).\n",
    "        \"\"\"\n",
    "        input_texts, targets = batch\n",
    "        _targets = targets\n",
    "        targets = targets.to(textattack.shared.utils.device)\n",
    "\n",
    "        if isinstance(model, transformers.PreTrainedModel):\n",
    "            input_ids = tokenizer(\n",
    "                input_texts,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "            )\n",
    "            input_ids.to(textattack.shared.utils.device)\n",
    "            logits = model(**input_ids)[0]\n",
    "        else:\n",
    "            input_ids = tokenizer(input_texts)\n",
    "            if not isinstance(input_ids, torch.Tensor):\n",
    "                input_ids = torch.tensor(input_ids)\n",
    "            input_ids = input_ids.to(textattack.shared.utils.device)\n",
    "            logits = model(input_ids)\n",
    "\n",
    "        if self.task_type == \"regression\":\n",
    "            preds = logits\n",
    "        else:\n",
    "            preds = logits.argmax(dim=-1)\n",
    "\n",
    "        return preds.cpu(), _targets\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model on given training dataset.\"\"\"\n",
    "        if not self.train_dataset:\n",
    "            raise ValueError(\"No `train_dataset` available for training.\")\n",
    "\n",
    "        textattack.shared.utils.set_seed(self.training_args.random_seed)\n",
    "        if not os.path.exists(self.training_args.output_dir):\n",
    "            os.makedirs(self.training_args.output_dir)\n",
    "\n",
    "        # Save logger writes to file\n",
    "        log_txt_path = os.path.join(self.training_args.output_dir, \"train_log.txt\")\n",
    "        fh = logging.FileHandler(log_txt_path)\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "        logger.addHandler(fh)\n",
    "        logger.info(f\"Writing logs to {log_txt_path}.\")\n",
    "\n",
    "        # Save original self.training_args to file\n",
    "        args_save_path = os.path.join(\n",
    "            self.training_args.output_dir, \"training_args.json\"\n",
    "        )\n",
    "        with open(args_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.training_args.__dict__, f)\n",
    "        logger.info(f\"Wrote original training args to {args_save_path}.\")\n",
    "\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        tokenizer = self.model_wrapper.tokenizer\n",
    "        model = self.model_wrapper.model\n",
    "\n",
    "        if self.training_args.parallel and num_gpus > 1:\n",
    "            # TODO: torch.nn.parallel.DistributedDataParallel\n",
    "            # Supposedly faster than DataParallel, but requires more work to setup properly.\n",
    "            model = torch.nn.DataParallel(model)\n",
    "            logger.info(f\"Training on {num_gpus} GPUs via `torch.nn.DataParallel`.\")\n",
    "            train_batch_size = self.training_args.per_device_train_batch_size * num_gpus\n",
    "        else:\n",
    "            train_batch_size = self.training_args.per_device_train_batch_size\n",
    "\n",
    "        if self.attack is None:\n",
    "            num_clean_epochs = self.training_args.num_epochs\n",
    "        else:\n",
    "            num_clean_epochs = self.training_args.num_clean_epochs\n",
    "\n",
    "        total_clean_training_steps = (\n",
    "            math.ceil(\n",
    "                len(self.train_dataset)\n",
    "                / (train_batch_size * self.training_args.gradient_accumulation_steps)\n",
    "            )\n",
    "            * num_clean_epochs\n",
    "        )\n",
    "        total_adv_training_steps = math.ceil(\n",
    "            (len(self.train_dataset) + self.training_args.num_train_adv_examples)\n",
    "            / (train_batch_size * self.training_args.gradient_accumulation_steps)\n",
    "        ) * (self.training_args.num_epochs - num_clean_epochs)\n",
    "\n",
    "        total_training_steps = total_clean_training_steps + total_adv_training_steps\n",
    "\n",
    "        optimizer, scheduler = self.get_optimizer_and_scheduler(\n",
    "            model, total_training_steps\n",
    "        )\n",
    "\n",
    "        self._print_training_args(\n",
    "            total_training_steps, train_batch_size, num_clean_epochs\n",
    "        )\n",
    "\n",
    "        model.to(textattack.shared.utils.device)\n",
    "\n",
    "        # Variables across epochs\n",
    "        self._total_loss = 0.0\n",
    "        self._current_loss = 0.0\n",
    "        self._last_log_step = 0\n",
    "\n",
    "        # `best_score` is used to keep track of the best model across training.\n",
    "        # Could be loss, accuracy, or other metrics.\n",
    "        best_eval_score = 0.0\n",
    "        best_eval_score_epoch = 0\n",
    "        best_model_path = None\n",
    "        epochs_since_best_eval_score = 0\n",
    "\n",
    "        for epoch in range(1, self.training_args.num_epochs + 1):\n",
    "            logger.info(\"==========================================================\")\n",
    "            logger.info(f\"Epoch {epoch}\")\n",
    "\n",
    "            if self.attack and epoch > num_clean_epochs:\n",
    "                if (\n",
    "                    epoch - num_clean_epochs - 1\n",
    "                ) % self.training_args.attack_epoch_interval == 0:\n",
    "                    # only generate a new adversarial training set every self.training_args.attack_period epochs after the clean epochs\n",
    "                    # adv_dataset is instance of `textattack.datasets.Dataset`\n",
    "                    model.eval()\n",
    "                    adv_dataset = self._generate_adversarial_examples(epoch)\n",
    "                    model.train()\n",
    "                    model.to(textattack.shared.utils.device)\n",
    "                else:\n",
    "                    adv_dataset = None\n",
    "            else:\n",
    "                logger.info(f\"Running clean epoch {epoch}/{num_clean_epochs}\")\n",
    "                adv_dataset = None\n",
    "\n",
    "            train_dataloader = self.get_train_dataloader(\n",
    "                self.train_dataset, adv_dataset, train_batch_size\n",
    "            )\n",
    "            model.train()\n",
    "            # Epoch variables\n",
    "            all_preds = []\n",
    "            all_targets = []\n",
    "            prog_bar = tqdm.tqdm(\n",
    "                train_dataloader,\n",
    "                desc=\"Iteration\",\n",
    "                position=0,\n",
    "                leave=True,\n",
    "                dynamic_ncols=True,\n",
    "            )\n",
    "            for step, batch in enumerate(prog_bar):\n",
    "                loss, preds, targets = self.training_step(model, tokenizer, batch)\n",
    "\n",
    "                if isinstance(model, torch.nn.DataParallel):\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                loss = loss / self.training_args.gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                loss = loss.item()\n",
    "                self._total_loss += loss\n",
    "                self._current_loss += loss\n",
    "\n",
    "                all_preds.append(preds)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "                if (step + 1) % self.training_args.gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    if scheduler:\n",
    "                        scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    self._global_step += 1\n",
    "\n",
    "                if self._global_step > 0:\n",
    "                    prog_bar.set_description(\n",
    "                        f\"Loss {self._total_loss/self._global_step:.5f}\"\n",
    "                    )\n",
    "\n",
    "                # TODO: Better way to handle TB and Wandb logging\n",
    "                if (self._global_step > 0) and (\n",
    "                    self._global_step % self.training_args.logging_interval_step == 0\n",
    "                ):\n",
    "                    lr_to_log = (\n",
    "                        scheduler.get_last_lr()[0]\n",
    "                        if scheduler\n",
    "                        else self.training_args.learning_rate\n",
    "                    )\n",
    "                    if self._global_step - self._last_log_step >= 1:\n",
    "                        loss_to_log = round(\n",
    "                            self._current_loss\n",
    "                            / (self._global_step - self._last_log_step),\n",
    "                            4,\n",
    "                        )\n",
    "                    else:\n",
    "                        loss_to_log = round(self._current_loss, 4)\n",
    "\n",
    "                    log = {\"train/loss\": loss_to_log, \"train/learning_rate\": lr_to_log}\n",
    "                    if self.training_args.log_to_tb:\n",
    "                        self._tb_log(log, self._global_step)\n",
    "\n",
    "                    if self.training_args.log_to_wandb:\n",
    "                        self._wandb_log(log, self._global_step)\n",
    "\n",
    "                    self._current_loss = 0.0\n",
    "                    self._last_log_step = self._global_step\n",
    "\n",
    "                # Save model checkpoint to file.\n",
    "                if self.training_args.checkpoint_interval_steps:\n",
    "                    if (\n",
    "                        self._global_step > 0\n",
    "                        and (\n",
    "                            self._global_step\n",
    "                            % self.training_args.checkpoint_interval_steps\n",
    "                        )\n",
    "                        == 0\n",
    "                    ):\n",
    "                        self._save_model_checkpoint(\n",
    "                            model, tokenizer, step=self._global_step\n",
    "                        )\n",
    "\n",
    "            preds = torch.cat(all_preds)\n",
    "            targets = torch.cat(all_targets)\n",
    "            if self._metric_name == \"accuracy\":\n",
    "                correct_predictions = (preds == targets).sum().item()\n",
    "                accuracy = correct_predictions / len(targets)\n",
    "                metric_log = {\"train/train_accuracy\": accuracy}\n",
    "                logger.info(f\"Train accuracy: {accuracy*100:.2f}%\")\n",
    "            else:\n",
    "                pearson_correlation, pearson_pvalue = scipy.stats.pearsonr(\n",
    "                    preds, targets\n",
    "                )\n",
    "                metric_log = {\n",
    "                    \"train/pearson_correlation\": pearson_correlation,\n",
    "                    \"train/pearson_pvalue\": pearson_pvalue,\n",
    "                }\n",
    "                logger.info(f\"Train Pearson correlation: {pearson_correlation:.4f}%\")\n",
    "\n",
    "            if len(targets) > 0:\n",
    "                if self.training_args.log_to_tb:\n",
    "                    self._tb_log(metric_log, epoch)\n",
    "                if self.training_args.log_to_wandb:\n",
    "                    metric_log[\"epoch\"] = epoch\n",
    "                    self._wandb_log(metric_log, self._global_step)\n",
    "\n",
    "            # Evaluate after each epoch.\n",
    "            eval_score = self.evaluate()\n",
    "\n",
    "            if self.training_args.log_to_tb:\n",
    "                self._tb_log({f\"eval/{self._metric_name}\": eval_score}, epoch)\n",
    "            if self.training_args.log_to_wandb:\n",
    "                self._wandb_log(\n",
    "                    {f\"eval/{self._metric_name}\": eval_score, \"epoch\": epoch},\n",
    "                    self._global_step,\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.training_args.checkpoint_interval_epochs\n",
    "                and (epoch % self.training_args.checkpoint_interval_epochs) == 0\n",
    "            ):\n",
    "                self._save_model_checkpoint(model, tokenizer, epoch=epoch)\n",
    "\n",
    "            if eval_score > best_eval_score:\n",
    "                best_eval_score = eval_score\n",
    "                best_eval_score_epoch = epoch\n",
    "                epochs_since_best_eval_score = 0\n",
    "                self._save_model_checkpoint(model, tokenizer, best=True)\n",
    "                logger.info(\n",
    "                    f\"Best score found. Saved model to {self.training_args.output_dir}/best_model/\"\n",
    "                )\n",
    "            else:\n",
    "                epochs_since_best_eval_score += 1\n",
    "                if self.training_args.early_stopping_epochs and (\n",
    "                    epochs_since_best_eval_score\n",
    "                    > self.training_args.early_stopping_epochs\n",
    "                ):\n",
    "                    logger.info(\n",
    "                        f\"Stopping early since it's been {self.training_args.early_stopping_epochs} steps since validation score increased.\"\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "        if self.training_args.log_to_tb:\n",
    "            self._tb_writer.flush()\n",
    "\n",
    "        # Finish training\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model = model.module\n",
    "\n",
    "        if self.training_args.load_best_model_at_end:\n",
    "            best_model_path = os.path.join(self.training_args.output_dir, \"best_model\")\n",
    "            if hasattr(model, \"from_pretrained\"):\n",
    "                model = model.__class__.from_pretrained(best_model_path)\n",
    "            else:\n",
    "                model = model.load_state_dict(\n",
    "                    torch.load(os.path.join(best_model_path, \"pytorch_model.bin\"))\n",
    "                )\n",
    "\n",
    "        if self.training_args.save_last:\n",
    "            self._save_model_checkpoint(model, tokenizer, last=True)\n",
    "\n",
    "        self.model_wrapper.model = model\n",
    "        self._write_readme(best_eval_score, best_eval_score_epoch, train_batch_size)\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the model on given evaluation dataset.\"\"\"\n",
    "\n",
    "        if not self.eval_dataset:\n",
    "            raise ValueError(\"No `eval_dataset` available for training.\")\n",
    "\n",
    "        logging.info(\"Evaluating model on evaluation dataset.\")\n",
    "        model = self.model_wrapper.model\n",
    "        tokenizer = self.model_wrapper.tokenizer\n",
    "\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            num_gpus = torch.cuda.device_count()\n",
    "            eval_batch_size = self.training_args.per_device_eval_batch_size * num_gpus\n",
    "        else:\n",
    "            eval_batch_size = self.training_args.per_device_eval_batch_size\n",
    "\n",
    "        eval_dataloader = self.get_eval_dataloader(self.eval_dataset, eval_batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step, batch in enumerate(eval_dataloader):\n",
    "                preds, targets = self.evaluate_step(model, tokenizer, batch)\n",
    "                all_preds.append(preds)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "        preds = torch.cat(all_preds)\n",
    "        targets = torch.cat(all_targets)\n",
    "\n",
    "        if self.task_type == \"regression\":\n",
    "            pearson_correlation, pearson_p_value = scipy.stats.pearsonr(preds, targets)\n",
    "            eval_score = pearson_correlation\n",
    "        else:\n",
    "            correct_predictions = (preds == targets).sum().item()\n",
    "            accuracy = correct_predictions / len(targets)\n",
    "            eval_score = accuracy\n",
    "\n",
    "        if self._metric_name == \"accuracy\":\n",
    "            logger.info(f\"Eval {self._metric_name}: {eval_score*100:.2f}%\")\n",
    "        else:\n",
    "            logger.info(f\"Eval {self._metric_name}: {eval_score:.4f}%\")\n",
    "\n",
    "        return eval_score\n",
    "\n",
    "\n",
    "    def _write_readme(self, best_eval_score, best_eval_score_epoch, train_batch_size):\n",
    "        if isinstance(self.training_args, CommandLineTrainingArgs):\n",
    "            model_name = self.training_args.model_name_or_path\n",
    "        elif isinstance(self.model_wrapper.model, transformers.PreTrainedModel):\n",
    "            if (\n",
    "                hasattr(self.model_wrapper.model.config, \"_name_or_path\")\n",
    "                and self.model_wrapper.model.config._name_or_path in HUGGINGFACE_MODELS\n",
    "            ):\n",
    "                # TODO Better way than just checking HUGGINGFACE_MODELS ?\n",
    "                model_name = self.model_wrapper.model.config._name_or_path\n",
    "            elif hasattr(self.model_wrapper.model.config, \"model_type\"):\n",
    "                model_name = self.model_wrapper.model.config.model_type\n",
    "            else:\n",
    "                model_name = \"\"\n",
    "        else:\n",
    "            model_name = \"\"\n",
    "\n",
    "        if model_name:\n",
    "            model_name = f\"`{model_name}`\"\n",
    "\n",
    "        if (\n",
    "            isinstance(self.training_args, CommandLineTrainingArgs)\n",
    "            and self.training_args.model_max_length\n",
    "        ):\n",
    "            model_max_length = self.training_args.model_max_length\n",
    "        elif isinstance(\n",
    "            self.model_wrapper.model,\n",
    "            (\n",
    "                transformers.PreTrainedModel,\n",
    "                LSTMForClassification,\n",
    "                WordCNNForClassification,\n",
    "            ),\n",
    "        ):\n",
    "            model_max_length = self.model_wrapper.tokenizer.model_max_length\n",
    "        else:\n",
    "            model_max_length = None\n",
    "\n",
    "        if model_max_length:\n",
    "            model_max_length_str = f\" a maximum sequence length of {model_max_length},\"\n",
    "        else:\n",
    "            model_max_length_str = \"\"\n",
    "\n",
    "        if isinstance(\n",
    "            self.train_dataset, textattack.datasets.HuggingFaceDataset\n",
    "        ) and hasattr(self.train_dataset, \"_name\"):\n",
    "            dataset_name = self.train_dataset._name\n",
    "            if hasattr(self.train_dataset, \"_subset\"):\n",
    "                dataset_name += f\" ({self.train_dataset._subset})\"\n",
    "        elif isinstance(\n",
    "            self.eval_dataset, textattack.datasets.HuggingFaceDataset\n",
    "        ) and hasattr(self.eval_dataset, \"_name\"):\n",
    "            dataset_name = self.eval_dataset._name\n",
    "            if hasattr(self.eval_dataset, \"_subset\"):\n",
    "                dataset_name += f\" ({self.eval_dataset._subset})\"\n",
    "        else:\n",
    "            dataset_name = None\n",
    "\n",
    "        if dataset_name:\n",
    "            dataset_str = (\n",
    "                \"and the `{dataset_name}` dataset loaded using the `datasets` library\"\n",
    "            )\n",
    "        else:\n",
    "            dataset_str = \"\"\n",
    "\n",
    "        loss_func = (\n",
    "            \"mean squared error\" if self.task_type == \"regression\" else \"cross-entropy\"\n",
    "        )\n",
    "        metric_name = (\n",
    "            \"pearson correlation\" if self.task_type == \"regression\" else \"accuracy\"\n",
    "        )\n",
    "        epoch_info = f\"{best_eval_score_epoch} epoch\" + (\n",
    "            \"s\" if best_eval_score_epoch > 1 else \"\"\n",
    "        )\n",
    "        readme_text = f\"\"\"\n",
    "            ## TextAttack Model Card\n",
    "\n",
    "            This {model_name} model was fine-tuned using TextAttack{dataset_str}. The model was fine-tuned\n",
    "            for {self.training_args.num_epochs} epochs with a batch size of {train_batch_size},\n",
    "            {model_max_length_str} and an initial learning rate of {self.training_args.learning_rate}.\n",
    "            Since this was a {self.task_type} task, the model was trained with a {loss_func} loss function.\n",
    "            The best score the model achieved on this task was {best_eval_score}, as measured by the\n",
    "            eval set {metric_name}, found after {epoch_info}.\n",
    "\n",
    "            For more information, check out [TextAttack on Github](https://github.com/QData/TextAttack).\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "        readme_save_path = os.path.join(self.training_args.output_dir, \"README.md\")\n",
    "        with open(readme_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(readme_text.strip() + \"\\n\")\n",
    "        logger.info(f\"Wrote README to {readme_save_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Writing logs to ./outputs/2023-10-19-21-58-08-248160/train_log.txt.\n",
      "textattack: Wrote original training args to ./outputs/2023-10-19-21-58-08-248160/training_args.json.\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "textattack: ***** Running training *****\n",
      "textattack:   Num examples = 3003\n",
      "textattack:   Num epochs = 1\n",
      "textattack:   Num clean epochs = 0\n",
      "textattack:   Instantaneous batch size per device = 1\n",
      "textattack:   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "textattack:   Gradient accumulation steps = 1\n",
      "textattack:   Total optimization steps = 3023\n",
      "textattack: ==========================================================\n",
      "textattack: Epoch 1\n",
      "textattack: Attacking model to generate new adversarial training set...\n",
      "[Succeeded / Failed / Skipped / Total] 20 / 103 / 6 / 129: 100%|██████████| 20/20 [05:31<00:00, 16.58s/it]\n",
      "textattack: Total number of attack results: 129\n",
      "textattack: Attack success rate: 16.26% [20 / 123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 0.54983: 100%|██████████| 3023/3023 [42:11<00:00,  1.19it/s] \n",
      "textattack: Train accuracy: 72.44%\n",
      "textattack: Eval accuracy: 86.31%\n",
      "textattack: Best score found. Saved model to ./outputs/2023-10-19-21-58-08-248160/best_model/\n",
      "textattack: Wrote README to ./outputs/2023-10-19-21-58-08-248160/README.md.\n",
      "textattack: Eval accuracy: 86.31%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8631415241057543"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_attack_trainer = Trainer(\n",
    "    model_wrapper,\n",
    "    \"classification\",\n",
    "    custom_attack,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    training_args\n",
    ")\n",
    "custom_attack_trainer.train()\n",
    "\n",
    "custom_attack_trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Bert attack trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_attack_trainer = textattack.Trainer(\n",
    "    model_wrapper,\n",
    "    \"classification\",\n",
    "    bert_attack,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    training_args\n",
    ")\n",
    "bert_attack_trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the adverserial trained models\n",
    "\n",
    "#### Custom attack trainer evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Eval accuracy: 86.31%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8631415241057543"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_attack_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.9\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 1 / 5:  25%|██▌       | 5/20 [00:12<00:37,  2.50s/it]textattack: Saving checkpoint under \"checkpoints/1697750815263.ta.chkpt\" at 2023-10-19 23:26:55 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 2 / 10:  50%|█████     | 10/20 [00:21<00:21,  2.15s/it]textattack: Saving checkpoint under \"checkpoints/1697750824246.ta.chkpt\" at 2023-10-19 23:27:04 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 3 / 15:  75%|███████▌  | 15/20 [00:30<00:10,  2.04s/it]textattack: Saving checkpoint under \"checkpoints/1697750833296.ta.chkpt\" at 2023-10-19 23:27:13 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 13 / 3 / 20: 100%|██████████| 20/20 [00:41<00:00,  2.07s/it]textattack: Saving checkpoint under \"checkpoints/1697750844143.ta.chkpt\" at 2023-10-19 23:27:24 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 13 / 3 / 20: 100%|██████████| 20/20 [00:41<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 4      |\n",
      "| Number of failed attacks:     | 13     |\n",
      "| Number of skipped attacks:    | 3      |\n",
      "| Original accuracy:            | 85.0%  |\n",
      "| Accuracy under attack:        | 65.0%  |\n",
      "| Attack success rate:          | 23.53% |\n",
      "| Average perturbed word %:     | 19.79% |\n",
      "| Average num. words per input: | 9.0    |\n",
      "| Avg num queries:              | 15.18  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31f22a010>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d266150>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x32b907b90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32d00fbd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x325125190>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31d3dfd10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32ae50350>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d01c550>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32c115210>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x32d161990>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32644d910>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32d22b890>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x32c03aa90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c42b2d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32c04b610>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32c714450>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x32bc6e5d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x325127610>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x31dbf2e10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x32c3403d0>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification(config)\n",
    "map_location=torch.device('cpu')\n",
    "model.load_state_dict(torch.load('/Users/marinjaprincipe/Documents/UZH/NPL/test/outputs/2023-10-19-21-58-08-248160/best_model/pytorch_model.bin', map_location=map_location))\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model.eval()\n",
    "model.to(map_location)\n",
    "# Run attack with defined dataset\n",
    "temp = list(validation_data.itertuples(index=False, name=None))\n",
    "dataset = textattack.datasets.Dataset(temp)\n",
    "\n",
    "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
    "attack_args = textattack.AttackArgs(num_examples=20, log_to_csv=\"log.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "custom_attacker = textattack.Attacker(custom_attack, dataset, attack_args)\n",
    "custom_attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert attack trainer evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_attack_trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
